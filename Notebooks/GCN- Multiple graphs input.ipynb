{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "DisjoingGraphs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "evRpH2mFxAQG"
      },
      "source": [
        "# !unzip output.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k69p31wtxVTP",
        "outputId": "1d9223ac-3c1b-4056-d17c-ef50aed75fe8"
      },
      "source": [
        "!pip install spektral"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spektral in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral) (2.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spektral) (2.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral) (4.41.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->spektral) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2020.12.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.3.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (56.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XCcqWXrz4_z"
      },
      "source": [
        "from spektral.layers import GCNConv\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfQOPlQp7YTb"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import Dataset, DisjointLoader, Graph\n",
        "from spektral.layers import GCSConv, GlobalAvgPool\n",
        "from spektral.layers.pooling import TopKPool\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import pdb"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD0qZF0dwSPO",
        "outputId": "ed7a00e1-66d1-4ab0-a74e-052df3451d3e"
      },
      "source": [
        "################################################################################\n",
        "# PARAMETERS\n",
        "################################################################################\n",
        "learning_rate = 1e-2  # Learning rate\n",
        "epochs = 400  # Number of training epochs\n",
        "es_patience = 10  # Patience for early stopping\n",
        "batch_size = 2  # Batch size\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# LOAD DATA\n",
        "################################################################################\n",
        "import sys\n",
        "from spektral.data import Dataset, Graph\n",
        "# sys.path.append('../lib')\n",
        "# from data_pre_processing import load_data\n",
        "# sys.path.remove('../lib')\n",
        "from spektral.layers import GCNConv\n",
        "from spektral.models.gcn import GCN\n",
        "from spektral.transforms import AdjToSpTensor, LayerPreprocess\n",
        "\n",
        "def load_data(circuit_name, path_to_data=\"data\", normalize=False):\n",
        "    \"\"\"Load data.\"\"\"\n",
        "    names = [\"x\", \"y\", \"graph\"]\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(f\"{path_to_data}/{circuit_name}.{names[i]}\", \"rb\") as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding=\"latin1\"))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "\n",
        "    x, y, graph = tuple(objects)\n",
        "\n",
        "    features = sp.csr_matrix(x).astype(int)\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph)).astype(int)\n",
        "    labels = np.array(y).reshape((-1,1))\n",
        "\n",
        "    print(adj.shape)\n",
        "    print(features.shape)\n",
        "    return adj, features, labels\n",
        "\n",
        "\n",
        "class CircuitDataset(Dataset):\n",
        "    def read(self):\n",
        "        circuits = []\n",
        "        circs = ['c6288', 'c17', 'c5315', 'c432', 'c499', 'c880', 'c1355', 'c1908', 'c3540']\n",
        "        # circs = ['c17']\n",
        "        for circ in circs:\n",
        "            A, X, labels = load_data(circ, 'output', normalize=\"\")\n",
        "            circuits.append(Graph(x=X.toarray(), a=A, y=labels))\n",
        "            print(f\"{circ}: {sum(labels)}, {len(labels)}\")\n",
        "        return circuits\n",
        "\n",
        "dataset = CircuitDataset(transforms=NormalizeAdj())\n",
        "\n",
        "# Parameters\n",
        "F = dataset.n_node_features  # Dimension of node features\n",
        "n_out = dataset.n_labels  # Dimension of the target\n",
        "\n",
        "# Train/valid/test split\n",
        "idxs = np.random.permutation(len(dataset))\n",
        "split_va, split_te = int(0.8 * len(dataset)), int(0.9 * len(dataset))\n",
        "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
        "print(idx_tr, idx_va, idx_te)\n",
        "dataset_tr = dataset[idx_tr]\n",
        "dataset_va = dataset[idx_va]\n",
        "dataset_te = dataset[idx_te]\n",
        "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs, node_level=True)\n",
        "loader_va = DisjointLoader(dataset_va, batch_size=batch_size, node_level=True)\n",
        "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, node_level=True)\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6288, 6288)\n",
            "(6288, 4)\n",
            "c6288: [846], 6288\n",
            "(17, 17)\n",
            "(17, 4)\n",
            "c17: [2], 17\n",
            "(5315, 5315)\n",
            "(5315, 4)\n",
            "c5315: [599], 5315\n",
            "(432, 432)\n",
            "(432, 4)\n",
            "c432: [60], 432\n",
            "(499, 499)\n",
            "(499, 4)\n",
            "c499: [50], 499\n",
            "(880, 880)\n",
            "(880, 4)\n",
            "c880: [114], 880\n",
            "(1355, 1355)\n",
            "(1355, 4)\n",
            "c1355: [192], 1355\n",
            "(1908, 1908)\n",
            "(1908, 4)\n",
            "c1908: [257], 1908\n",
            "(3540, 3540)\n",
            "(3540, 4)\n",
            "c3540: [406], 3540\n",
            "[6 3 5 2 0 1 8] [4] [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LHP2_d3y53S",
        "outputId": "232a309a-4a85-4f64-9e47-b161ee60000d"
      },
      "source": [
        "channels = 16           # Number of channels in the first layer\n",
        "dropout = 0.5           # Dropout rate for the features\n",
        "l2_reg = 5e-4           # L2 regularization rate\n",
        "learning_rate = 1e-2    # Learning rate\n",
        "epochs = 200            # Number of training epochs\n",
        "es_patience = 10        # Patience for early stopping\n",
        "N = 4\n",
        "\n",
        "# Model definition\n",
        "X_in = Input(shape=(F, ))\n",
        "fltr_in = Input((None, ), sparse=True)\n",
        "\n",
        "dropout_1 = Dropout(dropout)(X_in)\n",
        "graph_conv_1 = GCNConv(channels,\n",
        "                         activation='relu',\n",
        "                         kernel_regularizer=l2(l2_reg),\n",
        "                         use_bias=False)([dropout_1, fltr_in])\n",
        "\n",
        "dropout_2 = Dropout(dropout)(graph_conv_1)\n",
        "graph_conv_2 = GCNConv(n_out,\n",
        "                         activation='softmax',\n",
        "                         use_bias=False)([dropout_2, fltr_in])\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_2)\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              weighted_metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "tbCallBack_GCN = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='./DetectFaultInCircuit',\n",
        ")\n",
        "callback_GCN = [tbCallBack_GCN]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 4)            0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_10 (GCNConv)           (None, 16)           64          dropout_10[0][0]                 \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 16)           0           gcn_conv_10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_11 (GCNConv)           (None, 1)            16          dropout_11[0][0]                 \n",
            "                                                                 input_12[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 80\n",
            "Trainable params: 80\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdww4jrBwSPb",
        "outputId": "ae55ed44-48b1-4147-995d-c26f38c5d833"
      },
      "source": [
        "opt = Adam(lr=learning_rate)\n",
        "loss_fn = CategoricalCrossentropy()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# FIT MODEL\n",
        "################################################################################\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs[:-1], training=True)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        loss += sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    acc = tf.reduce_mean(categorical_accuracy(target, predictions))\n",
        "    return loss, acc\n",
        "\n",
        "\n",
        "def evaluate(loader):\n",
        "    output = []\n",
        "    step = 0\n",
        "    while step < loader.steps_per_epoch:\n",
        "        step += 1\n",
        "        inputs, target = loader.__next__()\n",
        "        try:\n",
        "          pred = model(inputs[:-1], training=False)\n",
        "        except:\n",
        "          pdb.set_trace()\n",
        "        outs = (\n",
        "            loss_fn(target, pred),\n",
        "            tf.reduce_mean(categorical_accuracy(target, pred)),\n",
        "        )\n",
        "        output.append(outs)\n",
        "    return np.mean(output, 0)\n",
        "\n",
        "\n",
        "print(\"Fitting model\")\n",
        "current_batch = epoch = model_loss = model_acc = 0\n",
        "best_val_loss = np.inf\n",
        "best_weights = None\n",
        "patience = es_patience\n",
        "\n",
        "for batch in loader_tr:\n",
        "    outs = train_step(*batch)\n",
        "\n",
        "    model_loss += outs[0]\n",
        "    model_acc += outs[1]\n",
        "    current_batch += 1\n",
        "    if current_batch == loader_tr.steps_per_epoch:\n",
        "        model_loss /= loader_tr.steps_per_epoch\n",
        "        model_acc /= loader_tr.steps_per_epoch\n",
        "        epoch += 1\n",
        "\n",
        "        # Compute validation loss and accuracy\n",
        "        val_loss, val_acc = evaluate(loader_va)\n",
        "        print(\n",
        "            \"Ep. {} - Loss: {:.2f} - Acc: {:.2f} - Val loss: {:.2f} - Val acc: {:.2f}\".format(\n",
        "                epoch, model_loss, model_acc, val_loss, val_acc\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Check if loss improved for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience = es_patience\n",
        "            print(\"New best val_loss {:.3f}\".format(val_loss))\n",
        "            best_weights = model.get_weights()\n",
        "        else:\n",
        "            patience -= 1\n",
        "            if patience == 0:\n",
        "                print(\"Early stopping (best val_loss: {})\".format(best_val_loss))\n",
        "                break\n",
        "        model_loss = 0\n",
        "        model_acc = 0\n",
        "        current_batch = 0\n",
        "\n",
        "################################################################################\n",
        "# EVALUATE MODEL\n",
        "################################################################################\n",
        "print(\"Testing model\")\n",
        "model.set_weights(best_weights)  # Load best model\n",
        "test_loss, test_acc = evaluate(loader_te)\n",
        "print(\"Done. Test loss: {:.4f}. Test acc: {:.2f}\".format(test_loss, test_acc))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting model\n",
            "Ep. 1 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "New best val_loss 0.000\n",
            "Ep. 2 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 3 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 4 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 5 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 6 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 7 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 8 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 9 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 10 - Loss: 0.00 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Ep. 11 - Loss: 0.01 - Acc: 1.00 - Val loss: 0.00 - Val acc: 1.00\n",
            "Early stopping (best val_loss: 0.0)\n",
            "Testing model\n",
            "Done. Test loss: 0.0000. Test acc: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpzJ-RrNwSPe"
      },
      "source": [
        "data = dataset[4]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr69SlXd4Wzi",
        "outputId": "cadd665e-44bf-49bf-b557-1f3240212892"
      },
      "source": [
        "data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(n_nodes=17, n_node_features=4, n_edge_features=None, n_labels=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbilkFE24XSD"
      },
      "source": [
        "# model.predict([[data.x, data.a]])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxKznEH4ltT",
        "outputId": "75ea3fe7-cfa2-43fb-d6a5-c2e3b8a7d751"
      },
      "source": [
        "data.y.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(499, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMfm87Zg4rRD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}