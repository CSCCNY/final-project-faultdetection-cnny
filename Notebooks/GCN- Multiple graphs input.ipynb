{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evRpH2mFxAQG",
    "outputId": "857b84d4-360c-46b2-ba32-d92eaedf3e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open data/output.zip, data/output.zip.zip or data/output.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "# !unzip output.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k69p31wtxVTP",
    "outputId": "5f7b7761-5174-4924-8981-fe14339d7c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spektral in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral) (0.22.2.post1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral) (1.1.5)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral) (4.2.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral) (2.23.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral) (1.0.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.4.1)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spektral) (2.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral) (4.41.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->spektral) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2018.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (3.0.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.12.4)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.32.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.7.4.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.10.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.4.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.12.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.12)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->spektral) (56.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.28.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.10.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7XCcqWXrz4_z"
   },
   "outputs": [],
   "source": [
    "from spektral.layers import GCNConv\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KfQOPlQp7YTb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from spektral.data import Dataset, DisjointLoader, Graph\n",
    "from spektral.layers import GCSConv, GlobalAvgPool\n",
    "from spektral.layers.pooling import TopKPool\n",
    "from spektral.transforms.normalize_adj import NormalizeAdj\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import pdb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD0qZF0dwSPO",
    "outputId": "86ea698f-a279-4c5e-8652-e940d02d4eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6288, 6288)\n",
      "(6288, 4)\n",
      "c6288: [846.], 6288\n",
      "(17, 17)\n",
      "(17, 4)\n",
      "c17: [2.], 17\n",
      "(5315, 5315)\n",
      "(5315, 4)\n",
      "c5315: [599.], 5315\n",
      "(432, 432)\n",
      "(432, 4)\n",
      "c432: [60.], 432\n",
      "(499, 499)\n",
      "(499, 4)\n",
      "c499: [50.], 499\n",
      "(880, 880)\n",
      "(880, 4)\n",
      "c880: [114.], 880\n",
      "(1355, 1355)\n",
      "(1355, 4)\n",
      "c1355: [192.], 1355\n",
      "(1908, 1908)\n",
      "(1908, 4)\n",
      "c1908: [257.], 1908\n",
      "(3540, 3540)\n",
      "(3540, 4)\n",
      "c3540: [406.], 3540\n",
      "[7 3 0 2 4 1 6] [8] [5]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# PARAMETERS\n",
    "################################################################################\n",
    "learning_rate = 1e-2  # Learning rate\n",
    "epochs = 400  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 1  # Batch size\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# LOAD DATA\n",
    "################################################################################\n",
    "import sys\n",
    "from spektral.data import Dataset, Graph\n",
    "# sys.path.append('../lib')\n",
    "# from data_pre_processing import load_data\n",
    "# sys.path.remove('../lib')\n",
    "from spektral.layers import GCNConv\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.transforms import AdjToSpTensor, LayerPreprocess\n",
    "\n",
    "def load_data(circuit_name, path_to_data=\"data\", normalize=False):\n",
    "    \"\"\"Load data.\"\"\"\n",
    "    names = [\"x\", \"y\", \"graph\"]\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(f\"{path_to_data}/{circuit_name}.{names[i]}\", \"rb\") as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding=\"latin1\"))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, graph = tuple(objects)\n",
    "\n",
    "    features = sp.csr_matrix(x).astype('float32')\n",
    "    # adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph)).astype(int)\n",
    "    g = nx.DiGraph()\n",
    "    g.add_nodes_from(graph.keys())\n",
    "    for k, v in graph.items():\n",
    "      g.add_edges_from(([(k, t) for t in v]))\n",
    "      g.add_edges_from([(k, k)])\n",
    "    adj = nx.adjacency_matrix(g)\n",
    "    labels = np.array(y).astype('float32').reshape((-1,1))\n",
    "\n",
    "    print(adj.shape)\n",
    "    print(features.shape)\n",
    "    return adj, features, labels\n",
    "  \n",
    "def encode_label(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class CircuitDataset(Dataset):\n",
    "    def read(self):\n",
    "        circuits = []\n",
    "        circs = ['c6288', 'c17', 'c5315', 'c432', 'c499', 'c880', 'c1355', 'c1908', 'c3540']\n",
    "        # circs = ['c17']\n",
    "        for circ in circs:\n",
    "            A, X, labels = load_data(circ, '../data/output', normalize=\"\")\n",
    "            circuits.append(Graph(x=X.toarray(), a=A, y=labels))\n",
    "            print(f\"{circ}: {sum(labels)}, {len(labels)}\")\n",
    "        return circuits\n",
    "\n",
    "dataset = CircuitDataset(transforms=[LayerPreprocess(GCNConv)])\n",
    "\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "n_out = dataset.n_labels  # Dimension of the target\n",
    "\n",
    "# Train/valid/test split\n",
    "idxs = np.random.permutation(len(dataset))\n",
    "split_va, split_te = int(0.8 * len(dataset)), int(0.9 * len(dataset))\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "print(idx_tr, idx_va, idx_te)\n",
    "# [8 6 5 0 1 4 2] [3] [7]\n",
    "dataset_tr = dataset[idx_tr]\n",
    "dataset_va = dataset[idx_va]\n",
    "dataset_te = dataset[idx_te]\n",
    "# dataset_tr = dataset[[8,6,5,1,2, 0, 3, 4, 7]]\n",
    "# dataset_va = dataset[[0,3]]\n",
    "# dataset_te = dataset[4,7]\n",
    "# loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs, node_level=True)\n",
    "# loader_va = DisjointLoader(dataset_va, batch_size=batch_size, node_level=True)\n",
    "# loader_te = DisjointLoader(dataset_te, batch_size=batch_size, node_level=True)\n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs, node_level=True)\n",
    "loader_va = DisjointLoader(dataset_va, batch_size=batch_size, node_level=True)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, node_level=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-Hiec2Jh-uFv"
   },
   "outputs": [],
   "source": [
    "# loader_tr = DisjointLoader(dataset_tr, batch_size=dataset_tr.n_graphs, epochs=epochs, node_level=True)\n",
    "# batch = loader_tr.__next__()\n",
    "# inputs, target = batch\n",
    "# x, a, i = inputs\n",
    "# print(x.shape, a.shape, target.shape)\n",
    "# print(x.dtype, a.dtype, target.dtype)\n",
    "# sum([ g.n_nodes for g in dataset_tr ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wn_SYZAirrvq",
    "outputId": "5d0877bf-7e38-46ac-f7f0-4ff8ceeb95b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=432, n_node_features=4, n_edge_features=None, n_labels=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZsZPDKRJoSf",
    "outputId": "55cb3423-0f12-460c-9e2c-0e97489bb48c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20234"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = sum([ g.n_nodes for g in dataset.graphs ])\n",
    "n_out = 1\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LHP2_d3y53S",
    "outputId": "e5bd601b-6b66-4c74-f6ed-895dd617e40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_in:  (None, 4)\n",
      "drp 1 KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "graph conv 1 KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='gcn_conv/Relu:0', description=\"created by layer 'gcn_conv'\")\n",
      "drp 2 KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='dropout_1/Identity:0', description=\"created by layer 'dropout_1'\")\n",
      "drp 2 KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='dropout_1/Identity:0', description=\"created by layer 'dropout_1'\")\n",
      "graph conv 2 KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='gcn_conv_1/Relu:0', description=\"created by layer 'gcn_conv_1'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_conv (GCNConv)              (None, 50)           200         dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           gcn_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gcn_conv_2 (GCNConv)            (None, 1)            50          dropout_2[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 250\n",
      "Trainable params: 250\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "channels = 50          # Number of channels in the first layer\n",
    "dropout = 0.5           # Dropout rate for the features\n",
    "l2_reg = 5e-4           # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 1000            # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n",
    "# N = \n",
    "\n",
    "# Model definition\n",
    "X_in = Input(shape=(F, ))\n",
    "print(\"X_in: \", X_in.shape)\n",
    "fltr_in = Input((None, ), sparse=True)\n",
    "# mask_in = Input((None, ))\n",
    "\n",
    "dropout_1 = Dropout(dropout)(X_in)\n",
    "print(\"drp 1\", dropout_1)\n",
    "graph_conv_1 = GCNConv(channels,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([dropout_1, fltr_in])\n",
    "print(\"graph conv 1\", graph_conv_1)\n",
    "dropout_2 = Dropout(dropout)(graph_conv_1)\n",
    "print(\"drp 2\", dropout_2)\n",
    "graph_conv_2 = GCNConv(channels,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([dropout_2, fltr_in])\n",
    "dropout_3 = Dropout(dropout)(graph_conv_1)\n",
    "print(\"drp 2\", dropout_2)\n",
    "graph_conv_3 = GCNConv(n_out,\n",
    "                         activation='sigmoid',\n",
    "                         use_bias=False)([dropout_3, fltr_in])\n",
    "print(\"graph conv 2\", graph_conv_2)\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_3)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "# model.compile(optimizer=optimizer,\n",
    "#               loss='categorical_crossentropy',\n",
    "#               weighted_metrics=['acc'])\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "tbCallBack_GCN = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./DetectFaultInCircuit',\n",
    ")\n",
    "callback_GCN = [tbCallBack_GCN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wWoMzeMPdxM6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import sparse_categorical_accuracy, binary_accuracy, binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from spektral.layers.ops import sp_matrix_to_sp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdww4jrBwSPb",
    "outputId": "77782094-c8aa-4e6c-e71c-84422d1c99a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_on_batch at 0x7fd5d4750510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_on_batch at 0x7fd5d4750510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_on_batch at 0x7fd5d4750510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Train loss: 43913.8150, acc: 0.7521 | Valid loss: 17388.7012, acc: 0.8853 | Test loss: 566.0920, acc: 0.8705\n",
      "Train loss: 37155.0580, acc: 0.7086 | Valid loss: 13034.7754, acc: 0.8740 | Test loss: 425.3871, acc: 0.8648\n",
      "Train loss: 33909.9789, acc: 0.6604 | Valid loss: 8666.3271, acc: 0.8359 | Test loss: 308.1677, acc: 0.8182\n",
      "Train loss: 28042.5621, acc: 0.6229 | Valid loss: 5070.2036, acc: 0.7703 | Test loss: 220.7516, acc: 0.6250\n",
      "Train loss: 29035.9724, acc: 0.5716 | Valid loss: 2239.0630, acc: 0.5116 | Test loss: 182.3976, acc: 0.4443\n",
      "Train loss: 24738.4734, acc: 0.5101 | Valid loss: 1579.2344, acc: 0.1441 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 23626.3851, acc: 0.4874 | Valid loss: 1623.7969, acc: 0.1263 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 25089.6869, acc: 0.4647 | Valid loss: 2049.3562, acc: 0.1206 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 23842.4135, acc: 0.4454 | Valid loss: 2277.2185, acc: 0.1186 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 24110.8251, acc: 0.4331 | Valid loss: 2384.0403, acc: 0.1181 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 23388.2210, acc: 0.4292 | Valid loss: 2442.1145, acc: 0.1144 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 21658.2152, acc: 0.4340 | Valid loss: 2321.6414, acc: 0.1201 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 21432.9512, acc: 0.4469 | Valid loss: 2271.1667, acc: 0.1254 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 20508.7516, acc: 0.4581 | Valid loss: 2125.3894, acc: 0.1274 | Test loss: 168.1138, acc: 0.3023\n",
      "Train loss: 20891.4193, acc: 0.4554 | Valid loss: 2129.7068, acc: 0.1297 | Test loss: 168.1138, acc: 0.3023\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "# loss_fn = SparseCategoricalCrossentropy()\n",
    "# loss_fn = BinaryCrossentropy()\n",
    "loss_fn = binary_crossentropy\n",
    "\n",
    "# def input_mask(target):\n",
    "#     minimum = tf.math.minimum(tf.reduce_sum(tf.dtypes.cast(target == 0, tf.int32)), tf.reduce_sum(tf.dtypes.cast(target == 1, tf.int32)))\n",
    "#     zeroes_index = tf.random.shuffle(tf.where(target == 0)[:,0])[:minimum]\n",
    "#     ones_index = tf.random.shuffle(tf.where(target == 1)[:,0])[:minimum]\n",
    "    \n",
    "#     stacked_inp = tf.reshape(tf.stack([zeroes_index, ones_index]), (-1,1))\n",
    "#     zeros_stack = tf.reshape(tf.stack([stacked_inp, tf.zeros((minimum*2,1), dtype='int64')], axis=1), (-1,2))\n",
    "#     sparsed_data = tf.SparseTensor(zeros_stack, tf.ones((minimum*2, )), target.shape)\n",
    "#     return tf.sparse.to_dense(tf.sparse.reorder(sparsed_data), default_value = 0. )\n",
    "\n",
    "def masked_loss_and_accuracy(target, predictions):\n",
    "#     values_keep = tf.gather( logits[0], idx_keep )\n",
    "    loss = loss_fn(target, predictions)\n",
    "    minimum = tf.math.minimum(tf.reduce_sum(tf.dtypes.cast(target == 0, tf.int32)), tf.reduce_sum(tf.dtypes.cast(target == 1, tf.int32)))\n",
    "    zeroes_index = tf.random.shuffle(tf.where(target == 0)[:,0])[:minimum]\n",
    "    ones_index = tf.random.shuffle(tf.where(target == 1)[:,0])[:minimum]\n",
    "    loss_zeroes =  tf.reduce_sum(tf.gather(loss, zeroes_index))\n",
    "    loss_ones = tf.reduce_sum(tf.gather(loss, ones_index))\n",
    "    loss = loss_zeroes + loss_ones\n",
    "#     loss = tf.reduce_mean(tf.multiply(loss, mask))\n",
    "    bin_acc = binary_accuracy(target, predictions)\n",
    "    acc = tf.reduce_mean(bin_acc)\n",
    "    return loss, acc\n",
    "\n",
    "# Training function\n",
    "@tf.function\n",
    "def train_on_batch(inputs, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs[:-1], training=True)\n",
    "        loss, acc = masked_loss_and_accuracy(target, predictions)\n",
    "        loss = loss + sum(model.losses)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    step = 0\n",
    "    results = []\n",
    "    for batch in loader:\n",
    "        step += 1\n",
    "        inputs, target = batch\n",
    "        predictions = model(inputs[:-1], training=False)\n",
    "        loss, acc = masked_loss_and_accuracy(target, predictions)\n",
    "        results.append((loss, acc, len(target)))  # Keep track of batch size\n",
    "        if step == loader.steps_per_epoch:\n",
    "            results = np.array(results)\n",
    "            return np.average(results[:, :-1], 0, weights=results[:, -1])\n",
    "\n",
    "patience = 10\n",
    "# Setup training\n",
    "best_val_loss = 99999\n",
    "current_patience = patience\n",
    "step = 0\n",
    "\n",
    "# Training loop\n",
    "results_tr = []\n",
    "for batch in loader_tr:\n",
    "    step += 1\n",
    "\n",
    "    # Training step\n",
    "    inputs, target = batch\n",
    "    loss, acc = train_on_batch(inputs, target)\n",
    "    results_tr.append((loss, acc, len(target)))\n",
    "\n",
    "    if step == loader_tr.steps_per_epoch:\n",
    "        results_va = evaluate(loader_va)\n",
    "        if results_va[0] < best_val_loss:\n",
    "            best_val_loss = results_va[0]\n",
    "            current_patience = patience\n",
    "            results_te = evaluate(loader_te)\n",
    "        else:\n",
    "            current_patience -= 1\n",
    "            if current_patience == 0:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        # Print results\n",
    "        results_tr = np.array(results_tr)\n",
    "        results_tr = np.average(results_tr[:, :-1], 0, weights=results_tr[:, -1])\n",
    "        print(\n",
    "            \"Train loss: {:.4f}, acc: {:.4f} | \"\n",
    "            \"Valid loss: {:.4f}, acc: {:.4f} | \"\n",
    "            \"Test loss: {:.4f}, acc: {:.4f}\".format(\n",
    "                *results_tr, *results_va, *results_te\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Reset epoch\n",
    "        results_tr = []\n",
    "        step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbilkFE24XSD",
    "outputId": "f1c78ac0-5b27-44da-a58d-760922064f7f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-742916f33c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_te\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GCN Classification Report: \\n {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \"\"\"\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_te = dataset[4].x\n",
    "A_te = dataset[4].a\n",
    "y_te = dataset[4].y\n",
    "\n",
    "y_pred = model.predict([X_te, A_te], batch_size=X_te.shape[0])\n",
    "report = classification_report(y_te, y_pred)\n",
    "print('GCN Classification Report: \\n {}'.format(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nxKznEH4ltT",
    "outputId": "e9cdb608-825d-4611-b2c8-f60932e3a0ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred >= 0.5).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.keras.metrics.binary_accuracy(y_te, y_pred).numpy()\n",
    "minimum = np.array([(y_te == 0).sum(), (y_te == 1).sum()]).min()\n",
    "zeroes_index = np.random.choice(np.where(y_te == 0)[0], minimum, replace=False)\n",
    "ones_index = np.random.choice(np.where(y_te == 1)[0], minimum, replace=False)\n",
    "mask = np.zeros_like(y_te)\n",
    "mask[zeroes_index] = 1\n",
    "mask[ones_index] = 1\n",
    "# np.multiply(bin_acc, mask).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tf.convert_to_tensor(y_te)\n",
    "minimum = tf.math.minimum(tf.reduce_sum(tf.dtypes.cast(target == 0, tf.int32)), tf.reduce_sum(tf.dtypes.cast(target == 1, tf.int32)))\n",
    "zeroes_index = tf.random.shuffle(tf.where(target == 0)[:,0])[:minimum]\n",
    "ones_index = tf.random.shuffle(tf.where(target == 1)[:,0])[:minimum]\n",
    "mask = tf.Variable(tf.zeros_like(target))\n",
    "stacked_inp = tf.reshape(tf.stack([zeroes_index, ones_index]), (-1,1))\n",
    "zeros_stack = tf.reshape(tf.stack([stacked_inp, tf.zeros((minimum*2,1), dtype='int64')], axis=1), (-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tf.convert_to_tensor(y_te)\n",
    "minimum = tf.math.minimum(tf.reduce_sum(tf.dtypes.cast(target == 0, tf.int32)), tf.reduce_sum(tf.dtypes.cast(target == 1, tf.int32)))\n",
    "zeroes_index = tf.random.shuffle(tf.where(target == 0))[:minimum, :]\n",
    "ones_index = tf.random.shuffle(tf.where(target == 1))[:minimum, :]\n",
    "mask = tf.Variable(tf.zeros_like(target))\n",
    "stacked_inp = tf.stack([zeroes_index, ones_index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]),\n",
       " TensorShape([50]),\n",
       " TensorShape([100, 1]),\n",
       " TensorShape([100]),\n",
       " TensorShape([499, 1]),\n",
       " TensorShape([100, 2]))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.SparseTensor(stacked_inp, tf.ones((minimum*2, )), target.shape)\n",
    "zeroes_index.shape, ones_index.shape, stacked_inp.shape, tf.ones((minimum*2, )).shape, target.shape, zeros_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsed_data = tf.SparseTensor(zeros_stack, tf.ones((minimum*2, )), target.shape)\n",
    "mask = tf.sparse.to_dense(tf.sparse.reorder(sparsed_data), default_value = 0. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=100.0>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(densed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_filtering( logits, top_k = 5):\n",
    "    \n",
    "    # a[...,1] equivalent to a[: ,: ,1 ]\n",
    "    indices_to_remove = logits < tf.math.top_k(logits,top_k)[0][..., -1, None]\n",
    "    # indices_to_remove is a tensor of bool values e.g. [ True, False, False, ..., True ]\n",
    "\n",
    "    # 1d indices\n",
    "    idx_remove = tf.where( indices_to_remove == 0 )[:,-1]\n",
    "    idx_keep = tf.where( indices_to_remove == 1 )[:,-1]\n",
    "    \n",
    "    values_remove = tf.tile( [-float('inf')], [tf.shape(idx_remove)[0]] ) \n",
    "    values_keep = tf.gather( logits[0], idx_keep )\n",
    "\n",
    "    # to create a sparse vector we still need 2d indices like [ [0,1], [0,2], [0,10] ]\n",
    "    # create vectors of 0's that we'll later stack with the actual indices\n",
    "    zeros_remove = tf.zeros_like(idx_remove)\n",
    "    zeros_keep = tf.zeros_like(idx_keep)\n",
    "\n",
    "    idx_remove = tf.stack( [ zeros_remove, idx_remove], axis=1 )\n",
    "    idx_keep = tf.stack( [ zeros_keep, idx_keep], axis=1 )\n",
    "\n",
    "    # now we can create a sparse matrix\n",
    "    logits_remove = tf.SparseTensor( idx_remove, values_remove, tf.shape(logits, out_type = tf.int64))\n",
    "    logits_keep = tf.SparseTensor( idx_keep, values_keep, tf.shape(logits, out_type = tf.int64))\n",
    "\n",
    "    # add together the two matrices (need to convert them to dense first)\n",
    "    filtered_logits = tf.add(\n",
    "        tf.sparse.to_dense(logits_remove, default_value = 0. ),\n",
    "        tf.sparse.to_dense(logits_keep, default_value = 0. )\n",
    "    )\n",
    "\n",
    "    return filtered_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 432), dtype=bool, numpy=\n",
       "array([[ True, False, False, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True, False, ..., False, False, False]])>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sequence_mask([1, 3, 2], target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smipV5W2jGKf",
    "outputId": "8a06bd66-4448-46b1-b227-3c8e0453f2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5be3ae4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# layer_outputs = [layer.output for layer in model.layers]\n",
    "# activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "# activations = activation_model.predict([X_te, A_te],batch_size=X_te.shape[0])\n",
    "\n",
    "# #Get t-SNE Representation\n",
    "# #get the hidden layer representation after the first GCN layer\n",
    "# x_tsne = TSNE(n_components=2).fit_transform(activations[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "0F-uDNB4jKI8"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def plot_tSNE(labels_encoded,x_tsne):\n",
    "#     color_map = np.argmax(labels_encoded, axis=1)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     for cl in range(1):\n",
    "#         indices = np.where(color_map==cl)\n",
    "#         indices = indices[0]\n",
    "#         plt.scatter(x_tsne[indices,0], x_tsne[indices, 1], label=cl)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_tSNE(y_te,x_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upDQ-QBb4m89",
    "outputId": "b5b794de-6b38-4e19-a8d3-1c063d008e75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true = [[1], [1], [0], [0]]\n",
    "# y_pred = [[1], [1], [0], [0]]\n",
    "tf.keras.metrics.binary_accuracy(y_te, y_pred).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tj8IKy53HxWx",
    "outputId": "b81aa017-ca2a-4fb4-80ed-fe2a2c125c44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_te == 0).sum(), (y_te == 1).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCGZgvB1Kg2m",
    "outputId": "4a7d2f7d-1d07-43d2-e772-0f0d70963f38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "nVfU7bmKKvkz"
   },
   "outputs": [],
   "source": [
    "y_true = [[1], [1], [0], [0]]\n",
    "y_pred = [[0.8], [0.8], [0.3], [0.3]]\n",
    "m = tf.keras.metrics.binary_accuracy(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfSffWD9MANQ",
    "outputId": "87c348ae-42d1-4c7f-bf6e-58c15df7951a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36716142],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36708796],\n",
       "       [0.36763102],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.36541492],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.37839413],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.3813891 ],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.38834843],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.39287794],\n",
       "       [0.40640447],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.4082654 ],\n",
       "       [0.4205025 ],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.39123335],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4269486 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4100087 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.4114372 ],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.37812722],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.25657254],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.25657254],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.25657254],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.25657254],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.25657254],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.25657254],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.25657254],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.31654048],\n",
       "       [0.3169052 ],\n",
       "       [0.25657254],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.2921846 ],\n",
       "       [0.12362692],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.41709712],\n",
       "       [0.20426184],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.38555086],\n",
       "       [0.26603675],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.3670572 ],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.29757047],\n",
       "       [0.27216393],\n",
       "       [0.27216393],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.05739915],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ],\n",
       "       [0.4045186 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NT6z43I9MA2k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DisjoingGraphs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
