{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nikitaacharya/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../lib/')\n",
    "import data_pre_processing\n",
    "from models.gcn import GCN\n",
    "sys.path.remove('../lib/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2708)\n",
      "(2708, 1433)\n"
     ]
    }
   ],
   "source": [
    "A, X, Y, train_idx, val_idx, test_idx = data_pre_processing.load_data('cora', '../data/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "import os\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.sparse.linalg as la\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.io as sio\n",
    "import pdb\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning parameters and path dataset\n",
    "\n",
    "num_total_iter_training = 3000\n",
    "learning_rate = 1e-2\n",
    "val_test_interval = 1\n",
    "num_hidden_feat = 16\n",
    "gamma = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_pre_processing.preprocess_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaacharya/anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:124: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# compute GCN adj matrix\n",
    "A_tilde = sp.csr_matrix(A)\n",
    "A_tilde.setdiag(1)\n",
    "D = A_tilde.sum(axis=1)\n",
    "\n",
    "D_rows, D_cols = D.nonzero()\n",
    "D_vals = [D[i,j] for i, j in zip(D_rows, D_cols)]\n",
    "D_vals = np.reciprocal(np.sqrt(np.asarray(D_vals)))\n",
    "\n",
    "D_inv_sqrt = sp.csr_matrix((D_vals, (range(len(D_vals)), range(len(D_vals)))))\n",
    "\n",
    "A_tilde = D_inv_sqrt.dot(A_tilde).dot(D_inv_sqrt)\n",
    "A_tilde = A_tilde.tocsr()\n",
    "A_tilde.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.api._v1.keras.layers' has no attribute 'xavier_initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8c862714543b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnum_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mGCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcost_train_avg\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/VLSICircuitFaultDetectionModel-DNN/lib/models/gcn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, A, X, Y, num_hidden_feat, learning_rate, gamma, idx_gpu)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;34m\"W0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 )\n\u001b[1;32m     45\u001b[0m                 self.W1 = tf.get_variable(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m       \u001b[0;31m# Placeholder for Google-internal contrib error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v1.keras.layers' has no attribute 'xavier_initializer'"
     ]
    }
   ],
   "source": [
    "num_exp = 10 #number of times training GCN over the given dataset\n",
    "\n",
    "list_all_acc = []\n",
    "list_all_cost_val_avg  = []\n",
    "list_all_data_cost_val_avg = []\n",
    "list_all_acc_val_avg   = []\n",
    "list_all_cost_test_avg = []\n",
    "list_all_acc_test_avg  = []\n",
    "\n",
    "num_done = 0\n",
    "for seed in range(num_exp):\n",
    "    GCNN = GCN(A_tilde, X, Y, num_hidden_feat, learning_rate=learning_rate, gamma=gamma)\n",
    "\n",
    "    cost_train_avg      = []\n",
    "    grad_norm_train_avg = []\n",
    "    acc_train_avg       = []\n",
    "    cost_test_avg       = []\n",
    "    grad_norm_test_avg  = []\n",
    "    acc_test_avg        = []\n",
    "    cost_val_avg        = []\n",
    "    data_cost_val_avg   = []\n",
    "    acc_val_avg         = []\n",
    "    iter_test           = []\n",
    "    list_training_time = list()\n",
    "\n",
    "    #Training code\n",
    "    for i in range(num_total_iter_training):\n",
    "        if (len(cost_train_avg) % val_test_interval) == 0:\n",
    "            #Print last training performance\n",
    "            if (len(cost_train_avg)>0):\n",
    "                print(\"[TRN] epoch = %03i, cost = %3.2e, |grad| = %.2e, acc = %3.2e (%03.2fs)\" % \\\n",
    "                (len(cost_train_avg), cost_train_avg[-1], grad_norm_train_avg[-1], acc_train_avg[-1], time.time() - tic))\n",
    "\n",
    "            #Validate the model\n",
    "            tic = time.time()\n",
    "            \n",
    "            feed_dict = {GCNN.idx_nodes: val_idx, GCNN.keep_prob:1.0}\n",
    "            acc_val, cost_val, data_cost_val = GCNN.session.run([GCNN.accuracy, GCNN.loss, GCNN.data_loss], feed_dict)\n",
    "            \n",
    "            data_cost_val_avg.append(data_cost_val)\n",
    "            cost_val_avg.append(cost_val)\n",
    "            acc_val_avg.append(acc_val)\n",
    "            print(\"[VAL] epoch = %03i, data_cost = %3.2e, cost = %3.2e, acc = %3.2e (%03.2fs)\" % \\\n",
    "                (len(cost_train_avg), data_cost_val_avg[-1], cost_val_avg[-1], acc_val_avg[-1],  time.time() - tic))\n",
    "\n",
    "            #Test the model\n",
    "            tic = time.time()\n",
    "            \n",
    "            feed_dict = {GCNN.idx_nodes: test_idx, GCNN.keep_prob:1.0}\n",
    "            acc_test, cost_test = GCNN.session.run([GCNN.accuracy, GCNN.loss], feed_dict)\n",
    "            \n",
    "            cost_test_avg.append(cost_test)\n",
    "            acc_test_avg.append(acc_test)\n",
    "            print(\"[TST] epoch = %03i, cost = %3.2e, acc = %3.2e (%03.2fs)\" % \\\n",
    "                (len(cost_train_avg), cost_test_avg[-1], acc_test_avg[-1],  time.time() - tic))\n",
    "            iter_test.append(len(cost_train_avg))\n",
    "\n",
    "        tic = time.time()\n",
    "\n",
    "        tic = time.time()\n",
    "        feed_dict = {GCNN.idx_nodes: train_idx, GCNN.keep_prob: 0.5}\n",
    "        \n",
    "        _, current_training_loss, norm_grad, current_acc_training = GCNN.session.run([GCNN.opt_step, GCNN.loss, GCNN.norm_grad, GCNN.accuracy], feed_dict) \n",
    "\n",
    "        training_time = time.time() - tic   \n",
    "\n",
    "        cost_train_avg.append(current_training_loss)\n",
    "        grad_norm_train_avg.append(norm_grad)\n",
    "        acc_train_avg.append(current_acc_training)\n",
    "\n",
    "    #Compute and print statistics of the last realized experiment\n",
    "    list_all_acc.append(100*(np.asarray(acc_test_avg)[np.asarray(data_cost_val_avg)==np.min(data_cost_val_avg)]))\n",
    "    list_all_cost_val_avg.append(cost_val_avg)\n",
    "    list_all_data_cost_val_avg.append(data_cost_val_avg)\n",
    "    list_all_acc_val_avg.append(acc_val_avg)\n",
    "    list_all_cost_test_avg.append(cost_test_avg)\n",
    "    list_all_acc_test_avg.append(acc_test_avg)\n",
    "\n",
    "    print('Num done: %d' % num_done)\n",
    "    print('Max accuracy on test set achieved: %f%%' % np.max(np.asarray(acc_test_avg)*100))\n",
    "    print('Max suggested accuracy: %f%%' % (100*(np.asarray(acc_test_avg)[np.asarray(data_cost_val_avg)==np.min(data_cost_val_avg)]),))\n",
    "    print('Current mean: %f%%' % np.mean(list_all_acc))\n",
    "    print('Current std: %f' % np.std(list_all_acc))\n",
    "\n",
    "    num_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
